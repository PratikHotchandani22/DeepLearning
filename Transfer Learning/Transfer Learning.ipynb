{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b93d42ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a9a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 13:14:09.390891: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-07-12 13:14:09.391059: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path of the saved model\n",
    "file_path = '/Users/pratikhotchandani/Downloads/Github/DeepLearning/Transfer Learning/artifacts/model.pkl'\n",
    "\n",
    "# Load the saved model from the file\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "944cc4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0e6223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before freezing weights flatten: True\n",
      "after freezing weights flatten: False\n",
      "before freezing weights dense: True\n",
      "after freezing weights dense: False\n",
      "before freezing weights leaky_re_lu: True\n",
      "after freezing weights leaky_re_lu: False\n",
      "before freezing weights dense_1: True\n",
      "after freezing weights dense_1: False\n",
      "before freezing weights leaky_re_lu_1: True\n",
      "after freezing weights leaky_re_lu_1: False\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265,802\n",
      "Trainable params: 202\n",
      "Non-trainable params: 265,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# freeze weights\n",
    "for layer in loaded_model.layers[: -1]:\n",
    "    print(f\"before freezing weights {layer.name}: {layer.trainable}\") \n",
    "    layer.trainable = False\n",
    "    print(f\"after freezing weights {layer.name}: {layer.trainable}\") \n",
    "\n",
    "# modify last layer for our problem statement\n",
    "base_layers = loaded_model.layers[:-1]\n",
    "\n",
    "new_model = tf.keras.models.Sequential(base_layers)\n",
    "new_model.add(\n",
    "    tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_layer\")\n",
    ")\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fa22e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_odd_even_labels(labels):\n",
    "    # odd = 0\n",
    "    # even = 1\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels[idx] = np.where(label%2 == 0, 1, 0)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a879e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2691a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin, y_test_bin, y_valid_bin = update_odd_even_labels([y_train, y_test, y_valid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "610fc157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 13:31:43.846527: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-07-12 13:31:43.978199: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-12 13:31:51.072428: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 - 8s - loss: 0.4348 - accuracy: 0.7931 - val_loss: 0.3629 - val_accuracy: 0.8400 - 8s/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 7s - loss: 0.3624 - accuracy: 0.8390 - val_loss: 0.3362 - val_accuracy: 0.8562 - 7s/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 7s - loss: 0.3428 - accuracy: 0.8501 - val_loss: 0.3207 - val_accuracy: 0.8636 - 7s/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 7s - loss: 0.3302 - accuracy: 0.8569 - val_loss: 0.3107 - val_accuracy: 0.8700 - 7s/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 7s - loss: 0.3211 - accuracy: 0.8614 - val_loss: 0.3024 - val_accuracy: 0.8734 - 7s/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 7s - loss: 0.3138 - accuracy: 0.8653 - val_loss: 0.2963 - val_accuracy: 0.8776 - 7s/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 7s - loss: 0.3078 - accuracy: 0.8681 - val_loss: 0.2914 - val_accuracy: 0.8798 - 7s/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 7s - loss: 0.3027 - accuracy: 0.8706 - val_loss: 0.2856 - val_accuracy: 0.8820 - 7s/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 7s - loss: 0.2984 - accuracy: 0.8730 - val_loss: 0.2817 - val_accuracy: 0.8830 - 7s/epoch - 4ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 7s - loss: 0.2946 - accuracy: 0.8756 - val_loss: 0.2781 - val_accuracy: 0.8862 - 7s/epoch - 4ms/step\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2837 - accuracy: 0.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2837076783180237, 0.8831000328063965]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = new_model.fit(X_train, y_train_bin, epochs=10,\n",
    "                validation_data=(X_valid, y_valid_bin), verbose=2)\n",
    "\n",
    "new_model.evaluate(X_test, y_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70f797f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4434844e-4540-4668-bbe9-cf259810e0dd/assets\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path including the directory where you want to store the model\n",
    "file_path = '/Users/pratikhotchandani/Downloads/Github/DeepLearning/Transfer Learning/transfer_learning_model.pkl'\n",
    "\n",
    "# Save the model to the specified file path\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(new_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a766556f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
